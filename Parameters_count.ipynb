{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122c5b99-b10b-4d55-bd76-04476baa7015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet + mobilenet_v2\n",
      "  Encoder params: 2.22M\n",
      "  Decoder params: 4.40M\n",
      "  Total params:   6.64M\n",
      "  FLOPs:          17.36 GFLOPs\n",
      "  Inference time: 4.83 ms/image\n",
      "\n",
      "Unet++ + mobilenet_v2\n",
      "  Encoder params: 2.22M\n",
      "  Decoder params: 4.60M\n",
      "  Total params:   6.84M\n",
      "  FLOPs:          21.78 GFLOPs\n",
      "  Inference time: 6.44 ms/image\n",
      "\n",
      "DeepLabV3 + mobilenet_v2\n",
      "  Encoder params: 2.22M\n",
      "  Decoder params: 10.42M\n",
      "  Total params:   12.67M\n",
      "  FLOPs:          51.47 GFLOPs\n",
      "  Inference time: 7.33 ms/image\n",
      "\n",
      "Unet + efficientnet-b0\n",
      "  Encoder params: 4.01M\n",
      "  Decoder params: 2.24M\n",
      "  Total params:   6.27M\n",
      "  FLOPs:          13.91 GFLOPs\n",
      "  Inference time: 8.28 ms/image\n",
      "\n",
      "Unet++ + efficientnet-b0\n",
      "  Encoder params: 4.01M\n",
      "  Decoder params: 2.56M\n",
      "  Total params:   6.58M\n",
      "  FLOPs:          24.20 GFLOPs\n",
      "  Inference time: 9.63 ms/image\n",
      "\n",
      "DeepLabV3 + efficientnet-b0\n",
      "  Encoder params: 4.01M\n",
      "  Decoder params: 3.30M\n",
      "  Total params:   7.33M\n",
      "  FLOPs:          13.97 GFLOPs\n",
      "  Inference time: 10.23 ms/image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import time\n",
    "from thop import profile\n",
    "\n",
    "def count_parametersWD(module):\n",
    "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "# Configurations to evaluate\n",
    "encoders = [\"mobilenet_v2\", \"efficientnet-b0\"]\n",
    "decoders = {\n",
    "    \"Unet\": smp.Unet,\n",
    "    \"Unet++\": smp.UnetPlusPlus,\n",
    "    \"DeepLabV3\": smp.DeepLabV3,\n",
    "}\n",
    "\n",
    "num_classes = 101   # use 101 for CropAndWeed\n",
    "in_channels = 3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Input resolution for FLOPs + inference test\n",
    "input_size = (1, in_channels, 512, 512)   # batch_size=1, 512x512 image\n",
    "dummy_input = torch.randn(input_size).to(device)\n",
    "\n",
    "for enc in encoders:\n",
    "    for dec_name, dec_class in decoders.items():\n",
    "        model = dec_class(\n",
    "            encoder_name=enc,\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=in_channels,\n",
    "            classes=num_classes,\n",
    "        ).to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Count params\n",
    "        encoder_params = count_parametersWD(model.encoder)\n",
    "        decoder_params = count_parametersWD(model.decoder)\n",
    "        total_params = count_parametersWD(model)\n",
    "\n",
    "        # FLOPs\n",
    "        macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "        gflops = macs / 1e9\n",
    "\n",
    "        # Inference time (average over N runs)\n",
    "        N = 50\n",
    "        with torch.no_grad():\n",
    "            # warmup\n",
    "            for _ in range(10):\n",
    "                _ = model(dummy_input)\n",
    "\n",
    "            torch.cuda.synchronize() if device == \"cuda\" else None\n",
    "            start = time.perf_counter()\n",
    "\n",
    "            for _ in range(N):\n",
    "                _ = model(dummy_input)\n",
    "            \n",
    "            torch.cuda.synchronize() if device == \"cuda\" else None\n",
    "            end = time.perf_counter()\n",
    "\n",
    "        avg_time = (end - start) / N * 1000  # ms per image\n",
    "\n",
    "        # Print results\n",
    "        print(f\"{dec_name} + {enc}\")\n",
    "        print(f\"  Encoder params: {encoder_params/1e6:.2f}M\")\n",
    "        print(f\"  Decoder params: {decoder_params/1e6:.2f}M\")\n",
    "        print(f\"  Total params:   {total_params/1e6:.2f}M\")\n",
    "        print(f\"  FLOPs:          {gflops:.2f} GFLOPs\")\n",
    "        print(f\"  Inference time: {avg_time:.2f} ms/image\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6565dd-ba1f-4b09-9ded-ecde7a34b243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
